# Решение команды SUAI dream team 

Для поднятия API необходимо использовать следующие команды:

```bash
sudo docker build -t app_api .  
sudo docker run -p 8000:8000 app_api
```

После запуска контейнера, эндпоинты в swagger будут доступны по следующему адресу:
```
http://localhost:8000/docs
```

## Директории и файлы проекта

### `/services`
#### `AgencyService.py`
Основная логика приложения
#### `ChatService.py`
Реализация логики чата пользователя с LLM LLama3
#### `GitService.py`
Взаимодействие с github
#### `LLMService.py`
Взаимодействие с LLM LLama3
#### `promts.py`
Функции, генерирющие промпты для LLM


### `/utils`
#### `get_repositories_url.py`
Утилиты для получения информации о репозитирии
#### `parser.py`
Утилиты для парсинга результатов ответов от модели LLama3

### `Dockerfile`
Докер-файл, необходимый для поднятия системы
### `cc.py`
### `info.py`
Файл, содержащий пример карты компетенции разработчика в формате json
### `main.py`
Главный файл проекта
### `test_llama.py`
Файл, содержащий тесты, связанные с взаимодействием с LLM, для разразботческих нужд
### `requirements.txt`
Список используемых python-библиотек с их версиями

